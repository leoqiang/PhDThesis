\chapter{Appendix Temporary}\label{ch:myappendix}
\todo{Temporarily put all appendix information at here, the final location will still need to be decided}

\ldots

\instructionsappendices


\section{Appendix A: expression compendium exploration 
functionalities}\label{apd:colombos}

COLOMBOS provides rich functionalities to create and/or edit expression 
'modules'. In chapter \ref{ch:distiller}, we explored the option that let 
COLOMBOS automatically identify relevant condition contrasts based on 
the user specified query gene(s).  Alternatively one can also 
specify the conditions in interests and letting COLOMBOS automatically identify 
the genes that are over-expressed or under-expressed in them. Furthermore, it 
is also possible to maintain the full control by specifying both the genes and 
the conditions in interests in order to check the behavior logged in the 
existing experimental data.

When specifying genes of interests, apart from manually inputting gene 
information, one can also select genes based on other annotations obtained from 
public databases, such as the transcription factor or sigma factor that 
regulates the gene’s transcription (\cite{Gama-Castro2008}), the pathway a gene 
belongs to (\cite{Karp2005}), or the transcription unit a gene belongs to 
(\cite{Karp2005}). 
These functionalities are available as options in the gene selection section 
of the module creation panel. 

Additionally, several alternative functions are provided to choose the 
condition contrasts besides the condition selection based on expression values 
as used here. In case one is interested in specific experiments, one can select 
them directly. When a user is interested in specific types of condition 
properties, a condition hierarchy is available. The properties are grouped into 
4 major categories: Genomic, Growth, Medium, and Treatment. Subcategories exist 
under each major category to further classify them. This functionality can be 
reached through option `By annotation' in the condition selection section 
of the module creation panel. One can also use the condition 
property ontology in a similar way by selecting `By ontology' in the condition 
selection section.

For automatic expression value based contrasts or genes selection procedures, 
the calculations used to score relevance of a contrast for 
a set of genes, similarity of genes across a set of contrasts, or variability 
of a gene across a set of contrasts, are explained in the following sections.  
In addition, we also explained the enrichment calculation, the user module data 
exportation, and the advantages for the registered users here.

Even more options are available when the user modifies an existing 
module. To check all available functionalities, we refer the online manual of 
COLOMBOS.



\subsection{Contrast relevance score}\label{apd:contrast-score}

The default relevance score $c$ of a condition contrast for a group
of genes is calculated as the absolute inverse coefficient of
variation of those genes’ expression values in this contrast. It
is defined as the absolute mean divided by the standard deviation
of the genes’ expression values:

\begin{equation}
c=\frac{|\mu|}{\sigma}
\end{equation}
 
On the one hand, for expression values of the same mean, the
higher the score, the less sparse the values are. It prioritizes
the contrasts where genes’ expression values are more
consistent. On the other hand, for expression values of the same
standard deviation, the higher the score, the higher the mean. It
prefers the contrasts where genes are highly expressed. The score
thus serves as a measure that values both magnitude of expression
change in response to a condition contrast, as well as coherence
of expression within that contrast. The score identifies the most
relevant contrasts as those where the genes 'act as one', showing
the same, preferentially large, magnitude of expression change
with individual variations ideally only constituting random
Gaussian noise. From this notion, the score represents the number
of standard deviations the mean expression value of this
distribution is situated away from $0$, and can be interpreted as a
$Z$-score for the selected genes' expression change as a
whole. (Note that in case of only one gene, the score of a
condition contrast is degraded to the absolute expression value
of that gene under it.)

We have also provided an alternative measure for the contrast
relevance (selectable by the box in the top right of the contrast
selection window) called 'M value cutoff'.  The score assigned to
the contrasts in this case is the minimum M value (i.e. the
logratio) for the considered genes in case all genes' M values
are positive, or the maximum absolute M value in case all genes'
M values are negative.  In case of both positive and negative M
values exist for the considered genes, the contrast gets a score
of 0.



\subsection{Gene similarity score}\label{apd:gene-score}

The default similarity between a gene and a module's mean
profile, is the \textit{Uncentered Pearson’s correlation} calculated based
on the formula:

\begin{equation}
r_v=\frac{1}{n}\sum_{i-1}^n(\dfrac{x_i}{\sigma_x^{(0)}})(\dfrac{y_i}{\sigma_y^{(0)}})
\end{equation}

% NOTE: using extra tags to control the math displayed inline with the text
% Ref: http://tex.stackexchange.com/questions/32824/show-inline-math-as-if-it-were-display-math
where $\textstyle\sigma_x^{(0)}=\sqrt{\frac{1}{n}\sum\limits_{i}x_i^2}$; and 
$\textstyle\sigma_y^{(0)}=\sqrt{\frac{1}{n}\sum\limits_{i}y_i^2}$
Here $x_i$ represents the candidate gene expression data at
condition contrast $i$, whereas $y_i$ represents a module’s mean
expression value at contrast $i$. $\sigma_x^{(0)}$ and
$\sigma_y^{(0)}$ are both uncentered standard deviations assuming
zero mean of the population, hence they are marked with
superscript ‘$(0)$’. The higher the $v_r$, the more similar the
expression profile of a gene is to a module’s mean expression
profile.

We have also provided an alternative measure for the gene
similarity (selectable by the box in the top right of the
contrast selection window) that calculates an uncentered version
of the \textit{Spearman rank correlation}. The Spearman rank correlation
is calculated in the same way as the Pearson correlation but on
the ranks of the data instead of the data itself. To calculate an
uncentered version, instead of ranking all values from low to
high, the positive logratios are ranked from low to high while
the negative logratios are ranked from high to low and then
assigned a negative sign; the mean rank is assumed $0$.  This
uncentered Spearman rank correlation, compared to the uncentered
Pearson correlation, has the advantage of being able to capture
non-linear similarities, but the disadvantage of ignoring the
actual magnitudes of expression changes and their distributions.

For ranking genes, there are three options provided based on the
uncentered (rank) correlation score calculated. First one is
‘positive’ which uses $v_r$ directly as final score.  The second
option ‘absolute’ takes $|v_r|$ . It ranks both correlated and
anti-correlated genes based solely on their similarities. Instead, 
the third option ‘negative’ takes $-v_r$ as a score to favor only 
the anti-correlated genes.



\subsection{Gene variability}\label{apd:gene-sd}

The variability of a gene's expression value $x$ for conditions $i=1,…,n$ is calculated as the uncentered standard deviation: 

\begin{equation}
\sigma_x^{(0)}=\sqrt{\frac{1}{n}\sum\limits_{i=1}^{n}x_i^2}
\end{equation}


\subsection{Enrichment calculation}\label{apd:enrichment}

The GO (Gene Ontology) enrichment $p$-value is calculated based on a 
\textbf{hypergeometric distribution}. The lower the $p$-value, the lower the 
chance of a GO term appearing in a random gene set having the same number of 
genes as the module in comparison, and the more significant a GO term is 
enriched in the module.
\todo{Add formula and brief explanations here}

\subsection{User module data export}\label{apd:data-download}

Once a module is created, it can be exported in the format described 
in Section \ref{sec:dist-format-col}. 
To do so first click the module in the workspace to show its 
overview tab. 
Then click the `download' button located at the up right corner of 
this tab to show the download window. 
This automatically sends a request to the server to generate the data file for 
the current module. 
When ready, a link to the generated data file will appear in the window. 
User can click it to save the module data.


\subsection{Registered users}\label{apd:colombos-user}\todo{extend and update 
it}

An anonymous user can use the analysis interface without logging in, but the 
data generated will be lost when the webpage is closed. A registered user has 
the advantage of being able to save the workspace, and load it again any other 
time when logged in. It takes only two steps to create a new user. After 
logging in, the `Data' menu in the workspace panel will have items 
`Load', `Save', and `Save As' enabled.

\todo{user information and workspace management panel}



\section{Appendix B: Magic supplementary methods}

\subsection{Preprocessing: probe to gene mapping}

A semi-automatic workflow has been developed to consistently
annotate probes (Figure \ref{fig:pmap}), i.e. to identify a unique target gene
for each probe whenever possible. In total we needed to map
209036 probes, originating from 27 different microarray
platforms. Target genes belong to the “Filtered Gene Set” (FGS)
of 5b RefGen v2 B73 maize genome release, since it contains only
the high quality gene predictions by removing possible
pseudogenes, transposons, contaminations, and low confidence
genes. Both the FGS Gene Model and the FGS Transcript Model are
used in our workflow, in order to achieve the highest possible
mapping coverage for assigning probes to their proper target
genes. The Gene Model contains full gene sequences, including
exons, introns, 3\textquotesingle\,UTRs, etc, while the Transcript Model contains
only transcript sequences, including splice variants. The
workflow consists of four major steps, as is illustrated in
Figure \ref{fig:pmap}. First, the collected probe sequences are BLASTed
against both the gene model and transcript model. Next,
one-to-one probe mappings are extracted by taking all unique hits
and identifying the top- hits from multiple hits. The
corresponding quality scores are calculated. In the third step,
results from the Gene Model BLAST and Transcript Model BLAST are
merged into a consistent probe to gene map by resolving possible
conflicts between one probe’s gene hit and transcript hit based
on the comparison of their quality scores. At last, the mappings
retained in previous step are subjected to an additional
filtering step to remove low quality hits. Note that we only do
quality filtering in the final step in order to maximize the
information retained to identify and resolve the potential
ambiguous probe sequences. The results are a high quality
one-to-one probe to gene mapping.


The results of the workflow are influenced by the characteristics
of the input probe sequences, which serve as BLAST query
sequences in step 1. We make a distinction between oligo and cDNA
probes (respectively 158694 and 60345 in total),. Oligo probe sequences
are short sequences of length less than 100 nucleotides, usually
sifted through a stringent selection process \cite{Leparc2009,Rouillard2003}. 
In contrast, cDNA sequences (which
we retrieved from NCBI GenBank based on the access id referred by
each probe in the platform specifications), are much longer
sequences with length varying between one hundred to several
thousand bases. Often generated as a single-pass read, they are
of varying quality, and some contain low complexity regions in
their sequence. The differences between these two groups are
reflected by the parameters used when applying our workflow on
them. In the initial BLAST step, an $e$-value cutoff $0.001$ is used
for oligo due to their shorter length. In contrast, a much
stricter $e$-value cutoff 1e-20 is applied for cDNA to avoid hits
over low quality regions and to compensate their longer sequence
length. Conversely, a stricter criterion for oligos is employed
to guarantee the mapping quality in the final filtering step, as
even small variances between probe and target sequences can have
a great influence on their binding specificity due to the short
sequence length. A looser criterion is utilized for cDNA assuming
that longer probe sequences can tolerate more sequence variation
and still bind the proper target transcripts.

In the next sections, the individual steps of the workflow, and
the results obtained from each step, will be discussed in greater
detail.

% NOTE: put the figure files in appendix at document root directory, so it can be found
\begin{figure}
	\centering
	\medskip
  	\includegraphics[width=1\textwidth]{workflow.jpg}
  	\caption[Probe to gene mapping workflow]
  	{Probe to gene mapping workflow. The workflow consists of four
  	steps. First, the probe sequences collected are BLASTed against
  	both the FGS Gene and Transcript Model. Next, one-to-one probe
  	mappings are extracted by taking all unique hits ($G_u$, $T_u$) and
  	identifying top-hits ($G_T$,$T_T$) from multiple hits ($G_m$,$T_m$). For all
  	hits the quality measurements $Q_{hit}$ and $D_q$ are calculated. In the
  	third step, results from Gene Model BLAST and Transcript Model
  	BLAST are merged into a consistent probe to gene map ($G_p$) by
  	resolving possible conflicts between one probe’s gene hit and
  	transcript hit using $Q_{hit}$. At last, $G_p$ is filtered to remove low
  	quality hits, resulting in a high quality one-to-one probe to
  	gene mapping.}
  	\label{fig:pmap}
\end{figure}


\subsection{Construction of the compendium} 

For the Affymetrix Maize Genome Array with GEO access number
GPL3042 and ArrayExpress A-AFFY-77, the gene expression
measurements are often reported in GEO and ArrayExpress as the
values summarized at the probe set level.  As however, for
different studies different data preprocessing and summary
statistics have been used, we did not rely on these stored
expression data. Rather we used the original probe level
intensities (Affymetrix *.CEL files), converted those into
summarized expression levels using our pipelines, as this
increases consistency. We refer with the ‘maize’ platform (term
used on the website) to this raw information at the individual
probe level.  The probe to probe set mapping was derived from the
Affymetrix cdf file. The probe set to the genome annotation was
derived from the Affymetrix platform annotation file available at
the company’s website.

Normalization was done as described previously (\cite{Engelen2011}): 
we normalize each chip separately.  Each biological sample
was denominated as either test or reference, and proper test and
reference samples were paired to define the ‘sample
contrast’. Next, for each ‘sample contrast’, the data originating
from the paired biological samples that define the contrast are
combined by taking log ratios. Log-ratio calculation removes chip
specific factors present in the data.

Because the older maize array design didn’t have enough capacity
to cover the full gene set using a single microarray, multiple
chips of the same technology, each with their own probes
targeting complementary gene sets were used. To normalize
multiple-chip platform we followed the same procedure as
mentioned above and normalized data for each chip
separately. Subsequently, per contrast, the log-ratios from
multiple chips are combined. Although the chips of a
multiple-chip platform are designed to be complementary, there
are a few genes only that are measured on more than one chip
generating multiple expression values per gene. To obtain a
single gene expression value per contrast, the median value is
taken over the multiple chips to obtain final expression values
for those genes.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Keep the following \cleardoublepage at the end of this file, 
% otherwise \includeonly includes empty pages.
\cleardoublepage

% vim: tw=70 nocindent expandtab foldmethod=marker foldmarker={{{}{,}{}}}
